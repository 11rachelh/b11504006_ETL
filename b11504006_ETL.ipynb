{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec7688e-2afe-471f-ba09-8ea51e5fbd71",
   "metadata": {},
   "source": [
    "## Get the query results of \"fmri & love\" from PubMed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40fb4209-0af8-496c-99b6-2a0e0578dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved C:\\Users\\USER\\github-classroom\\ntu-info\\neurosynth-etl-11rachelh\\PMC4863427.html (180,248 bytes)\n",
      "Saved C:\\Users\\USER\\github-classroom\\ntu-info\\neurosynth-etl-11rachelh\\PMC7223160.html (357,542 bytes)\n",
      "Saved C:\\Users\\USER\\github-classroom\\ntu-info\\neurosynth-etl-11rachelh\\PMC7223160.html (357,542 bytes)\n",
      "Saved C:\\Users\\USER\\github-classroom\\ntu-info\\neurosynth-etl-11rachelh\\PMC7264388.html (205,454 bytes)\n",
      "Saved C:\\Users\\USER\\github-classroom\\ntu-info\\neurosynth-etl-11rachelh\\PMC7264388.html (205,454 bytes)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "# List of PMC article URLs\n",
    "urls = [\n",
    "    \"https://pmc.ncbi.nlm.nih.gov/articles/PMC4863427\",\n",
    "    \"https://pmc.ncbi.nlm.nih.gov/articles/PMC7223160\",\n",
    "    \"https://pmc.ncbi.nlm.nih.gov/articles/PMC7264388\",\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/125.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://pmc.ncbi.nlm.nih.gov/\",\n",
    "}\n",
    "\n",
    "for url in urls:\n",
    "    pmcid = url.split(\"/\")[-1]\n",
    "    outfile = Path(f\"{pmcid}.html\")\n",
    "    with requests.Session() as s:\n",
    "        s.headers.update(headers)\n",
    "        resp = s.get(url, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        if not resp.encoding:\n",
    "            resp.encoding = \"utf-8\"\n",
    "        outfile.write_text(resp.text, encoding=resp.encoding)\n",
    "    print(f\"Saved {outfile.resolve()} ({outfile.stat().st_size:,} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272e2c6-195b-43bd-8111-7c1332ef5d79",
   "metadata": {},
   "source": [
    "# Extract PMIDs from a PubMed HTML page\n",
    "Here we use **BeautifulSoup** and **regular expressions** to extract PMIDs from a saved PubMed HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389e2dc3-e4ef-4156-96b2-2d71557de615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "HTML_PATH = Path('front_psychol_fmri_love.html')  # change this if needed\n",
    "html_text = HTML_PATH.read_text(encoding='utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0416d8d2-65ce-4e12-8652-90277d18d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26617535,27242579,32457675,32528365\n",
      "['26617535', '27242579', '32457675', '32528365']\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "meta = soup.find('meta', attrs={'name': 'log_displayeduids'})\n",
    "pmids_str=meta.get('content')\n",
    "print(pmids_str)\n",
    "pmids= re.findall(r'\\d+', pmids_str)\n",
    "# or simply pmids=pmids_str.split(',')\n",
    "print(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e21ab431-d12d-470e-824c-ada725a1e68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"text-embedding-nomic-embed-text-v1.5\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"meta-llama-3-8b-instruct\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"gemma-3-12b-it-qat\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"gemma-3-4b-it-qat\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"qwen2.5-14b-instruct-mlx\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"phi-3.5-mini-instruct\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"llama-3.2-3b-instruct\",\n",
      "            \"object\": \"model\",\n",
      "            \"owned_by\": \"organization_owner\"\n",
      "        }\n",
      "    ],\n",
      "    \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# See all the available models:\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:1234/v1/models\"\n",
    "response = requests.get(url)\n",
    "models = response.json()\n",
    "print(json.dumps(models, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90d67ddc-7931-46a6-8461-2affbf669c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test text -> text:\n",
    "\n",
    "url = \"http://localhost:1234/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gemma-3-4b-it-qat\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"1+1=?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "data = response.json()\n",
    "print(data[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4629998-7a68-416d-b700-7b229d1bada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This table presents the results of a structural analysis, likely from a neuroimaging study (such as fMRI). Here's a breakdown of what the table shows:\n",
      "\n",
      "**Overall Purpose:** The table identifies \"significant clusters of activity for the main effects of video type.\" This means researchers were examining how brain regions responded differently to different types of video content (e.g., action vs. nature, or educational vs. entertainment).\n",
      "\n",
      "**Columns Explained:**\n",
      "\n",
      "*   **Structural location:** This column indicates the brain region where a significant difference in activity was found.  The locations are described using abbreviations (e.g., \"Medial frontal pole,\" \"Sup. temporal gyrus\").\n",
      "*   **Voxels:** This represents the number of individual brain measurement points (voxels) within that region showing a significant difference in activity based on the video type.  A higher number indicates a more robust finding for that region.\n",
      "*   **Z-max:** This is the maximum Z-score within a cluster. The Z-score indicates how many standard deviations away from zero the maximum value is, and it's used to determine statistical significance.  Higher Z-scores suggest a stronger effect.\n",
      "*   **X:** This is the x coordinate of the center of the cluster in space (likely in millimeters).\n",
      "*   **Y:** This is the y coordinate of the center of the cluster.\n",
      "*   **Z:** This is the z coordinate of the center of the cluster.\n",
      "\n",
      "**Interpretation and Key Findings (based on the numbers):**\n",
      "\n",
      "*   **Strongest Effects:** The most prominent clusters are found in:\n",
      "    *   **Medial frontal pole (X=0, Y=64):**  This area shows a significant difference with a large number of voxels (848) and a high Z-score (5.18).\n",
      "    *   **Sup. temporal gyrus (X=50, Y=-2):**  Another region with a substantial number of voxels (363) and a Z-score of 4.66.\n",
      "    *   **Thalamus (X=2, Y=-6):**  85 voxels with a Z-score of 5.29\n",
      "*   **Smaller, but still significant clusters:**  The table also shows smaller clusters in areas like the occipital pole, putamen, hippocampus, and various regions of the superior occipital cortex.\n",
      "\n",
      "**Important Note:**  The numbers (Z-max, X, Y, Z) are relative to a \"neutral\" condition. The researchers likely used a control group (e.g., watching a blank screen) to establish the baseline activity, and then compared it to the different video conditions.\n",
      "\n",
      "**To give you a more specific interpretation, I would need context about:**\n",
      "\n",
      "*   What types of video were used in the study?\n",
      "*   What was the research question being investigated (e.g., how video affects attention, memory, emotion)?\n"
     ]
    }
   ],
   "source": [
    "# Test [image, text] -> text:\n",
    "\n",
    "import base64\n",
    "\n",
    "with open(\"32528365_Table3.jpg\", \"rb\") as f:\n",
    "    image_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gemma-3-4b-it-qat\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's this?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "data = response.json()\n",
    "print(data[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00d3d7-5f09-4878-8dda-edd2c4277b8a",
   "metadata": {},
   "source": [
    "# Write your own [X, Y, Z] coordinate extractor\n",
    "You can either extract the coordinates from *.html or *.pdf of the 3 target articles:\n",
    "\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC4863427\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC7223160\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC7264388\n",
    "\n",
    "You can assume you know what tables to extract, IF NEEDED. \n",
    "\n",
    "The sprint goal is to generate info_data.csv BY YOURSELF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b8c20bc-3b98-4f27-9d32-f97e4e39dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PMID    PMCID                                           Keywords  \\\n",
      "0  27242579  4863427  AI; MPFC; aMCC; fMRI; intrasexual competition;...   \n",
      "1  27242579  4863427  AI; MPFC; aMCC; fMRI; intrasexual competition;...   \n",
      "2  27242579  4863427  AI; MPFC; aMCC; fMRI; intrasexual competition;...   \n",
      "3  27242579  4863427  AI; MPFC; aMCC; fMRI; intrasexual competition;...   \n",
      "4  27242579  4863427  AI; MPFC; aMCC; fMRI; intrasexual competition;...   \n",
      "\n",
      "   Table   X   Y   Z  \n",
      "0      2   8  12  58  \n",
      "1      2 -30  22   4  \n",
      "2      2  42  10   0  \n",
      "3      2  -6  14  42  \n",
      "4      2 -62 -22  34  \n",
      "AI; MPFC; aMCC; fMRI; intrasexual competition; pain empathy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('info_data.csv')\n",
    "print(df.head())\n",
    "print(df['Keywords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a8432-f747-488e-999f-675b13decccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to b11504006_info_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Extraction handles multi-row headers (e.g., 'Coordinates' with x, y, z underneath), flattens headers, and extracts correct columns, including negative values\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "html_files = [\n",
    "    'PMC4863427.html',\n",
    "    'PMC7223160.html',\n",
    "    'PMC7264388.html',\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "def extract_keywords(soup, html_text):\n",
    "    meta_keywords = soup.find('meta', attrs={'name': 'citation_keywords'})\n",
    "    if meta_keywords and meta_keywords.get('content'):\n",
    "        return meta_keywords.get('content')\n",
    "    for tag in soup.find_all(['b', 'strong', 'h3', 'h4', 'p', 'span']):\n",
    "        if tag.get_text(strip=True).lower().startswith('keywords'):\n",
    "            next_text = ''\n",
    "            text = tag.get_text(separator=' ', strip=True)\n",
    "            if ':' in text:\n",
    "                next_text = text.split(':', 1)[1].strip()\n",
    "            if not next_text:\n",
    "                sibling = tag.find_next_sibling(text=True)\n",
    "                if sibling:\n",
    "                    next_text = sibling.strip()\n",
    "            if not next_text and tag.parent:\n",
    "                sibling = tag.parent.find_next_sibling(text=True)\n",
    "                if sibling:\n",
    "                    next_text = sibling.strip()\n",
    "            if next_text:\n",
    "                return next_text\n",
    "    kw_match = re.search(r'Keywords?[:\\s]+([\\w\\s;,-]+)', html_text, re.IGNORECASE)\n",
    "    if kw_match:\n",
    "        return kw_match.group(1).strip()\n",
    "    return ''\n",
    "\n",
    "def is_number(val):\n",
    "    try:\n",
    "        # Remove spaces between minus and number, e.g., '- 36' -> '-36'\n",
    "        val = re.sub(r'^-\\s+', '-', val.strip())\n",
    "        float(val)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def find_xyz_indices_from_multiline_header(header_rows):\n",
    "    n_cols = max(len(row) for row in header_rows)\n",
    "    flat_headers = [''] * n_cols\n",
    "    for row in header_rows:\n",
    "        for i in range(n_cols):\n",
    "            part = row[i].strip().lower() if i < len(row) else ''\n",
    "            if part:\n",
    "                if flat_headers[i]:\n",
    "                    flat_headers[i] += ' ' + part\n",
    "                else:\n",
    "                    flat_headers[i] = part\n",
    "    x_idx = y_idx = z_idx = None\n",
    "    for i, h in enumerate(flat_headers):\n",
    "        if x_idx is None and re.search(r'\\bx\\b', h):\n",
    "            x_idx = i\n",
    "        elif y_idx is None and re.search(r'\\by\\b', h):\n",
    "            y_idx = i\n",
    "        elif z_idx is None and re.search(r'\\bz\\b', h):\n",
    "            z_idx = i\n",
    "    if None not in (x_idx, y_idx, z_idx):\n",
    "        return x_idx, y_idx, z_idx\n",
    "    return None\n",
    "\n",
    "for html_file in html_files:\n",
    "    html_path = Path(html_file)\n",
    "    if not html_path.exists():\n",
    "        print(f\"File not found: {html_file}\")\n",
    "        continue\n",
    "    html_text = html_path.read_text(encoding='utf-8', errors='ignore')\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "    pmcid = re.search(r'PMC\\d+', html_file).group() if re.search(r'PMC\\d+', html_file) else ''\n",
    "\n",
    "    pmid = ''\n",
    "    meta_pmid = soup.find('meta', attrs={'name': 'citation_pmid'})\n",
    "    if meta_pmid:\n",
    "        pmid = meta_pmid.get('content')\n",
    "    else:\n",
    "        pmid_match = re.search(r'PMID[:\\s]+(\\d+)', html_text)\n",
    "        if pmid_match:\n",
    "            pmid = pmid_match.group(1)\n",
    "\n",
    "    keywords = extract_keywords(soup, html_text)\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "    for table_idx, table in enumerate(tables, 1):\n",
    "        rows = table.find_all('tr')\n",
    "        if not rows:\n",
    "            continue\n",
    "        header_rows = []\n",
    "        for row in rows[:2]:\n",
    "            cells = row.find_all(['th', 'td'])\n",
    "            if all(cell.name == 'th' for cell in cells):\n",
    "                header_rows.append([cell.get_text(strip=True) for cell in cells])\n",
    "        if not header_rows:\n",
    "            header_rows = [[cell.get_text(strip=True) for cell in rows[0].find_all(['th', 'td'])]]\n",
    "        xyz_indices = find_xyz_indices_from_multiline_header(header_rows)\n",
    "        if xyz_indices:\n",
    "            x_idx, y_idx, z_idx = xyz_indices\n",
    "            for row in rows[len(header_rows):]:\n",
    "                cols = [td.get_text(strip=True) for td in row.find_all(['td', 'th'])]\n",
    "                if len(cols) > max(x_idx, y_idx, z_idx):\n",
    "                    x_val, y_val, z_val = cols[x_idx], cols[y_idx], cols[z_idx]\n",
    "                    # Remove spaces between minus and number for each value\n",
    "                    x_val = re.sub(r'^-\\s+', '-', x_val.strip())\n",
    "                    y_val = re.sub(r'^-\\s+', '-', y_val.strip())\n",
    "                    z_val = re.sub(r'^-\\s+', '-', z_val.strip())\n",
    "                    if all(is_number(v) for v in [x_val, y_val, z_val]):\n",
    "                        x = float(x_val)\n",
    "                        y = float(y_val)\n",
    "                        z = float(z_val)\n",
    "                        results.append({\n",
    "                            'PMID': pmid,\n",
    "                            'PMCID': pmcid.replace('PMC',''),\n",
    "                            'Keywords': keywords,\n",
    "                            'Table': table_idx,\n",
    "                            'X': x,\n",
    "                            'Y': y,\n",
    "                            'Z': z,\n",
    "                        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('b11504006_info_data.csv', index=False)\n",
    "print('Saved to b11504006_info_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cad97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
